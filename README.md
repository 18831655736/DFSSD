# DFSSD: Deep Feature-aware Semi-Supervised Distillation

**DFSSD** is a deep learning-based framework for **industrial defect detection** under **semi-supervised learning** conditions. It leverages the concept of **teacher-student distillation** to train lightweight student models from large teacher models, achieving both high detection accuracy and low-latency inference.

## Table of Contents

1. [Introduction](#introduction)
2. [Installation](#installation)
3. [Usage](#usage)
4. [Training and Testing](#training-and-testing)

## Introduction

**DFSSD** (Deep Feature-aware Semi-Supervised Distillation) is designed for industrial defect detection, where annotated data is limited. By employing **distillation-based training**, it trains a compact student model from a teacher model with significantly fewer parameters while maintaining robust detection accuracy.

Key features:
- **Teacher-student distillation**: Compresses a large teacher model (YOLOv8s) to a smaller student model (YOLOv8n) while preserving high performance.
- **Semi-supervised learning**: Uses a minimal amount of labeled data and pseudo-labeled data generated by the teacher model.
- **High efficiency**: Focuses on low-latency inference, making it suitable for real-time applications.

## Installation

### Prerequisites

- Python >= 3.6
- PyTorch >= 1.7
- CUDA (optional for GPU acceleration)

### Installing Dependencies 

   pip install -r requirements.txt

## Usage

1. **Dataset**:
   This repository uses the **CR7-DET** dataset for training and testing. You can download the dataset from the following link:

   - [CR7-DET Dataset](<INSERT_YOUR_DATASET_LINK_HERE>)

   Make sure to download and place the dataset in the appropriate directory for training and testing.

2. **Data Splitting**: 
   The **CR7-DET** dataset is divided into **three subsets**:
   - **Training**: 80% of the dataset is used for training the model.
   - **Validation**: 10% of the dataset is reserved for validating the model during training.
   - **Testing**: 10% of the dataset is used for evaluating the final model after training is complete.

   This data split ensures that the model has a well-balanced distribution for:
   - **Training**: Learning from the labeled data.
   - **Validation**: Fine-tuning hyperparameters and model selection during training.
   - **Testing**: Final evaluation of the trained modelâ€™s performance.

3. **Preprocessing**: 
   The dataset undergoes several preprocessing steps to ensure consistency and to prepare it for training:
   - **Resizing**: All images are resized to a fixed size.
   - **Normalization**: The pixel values of the images are normalized to a standard range (e.g., 0 to 1 or -1 to 1).
   - **Augmentation**: Random augmentations are applied to improve model generalization (such as rotation, flipping, etc.).

   The preprocessing steps are implemented in `data/preprocessing.py`. You can modify the configuration in this script if you wish to adjust the preprocessing settings according to your needs.



## Training and Testing

To train the model, use the following command:

python train.py --teacher_model <path_to_teacher_model> --student_model <path_to_student_model> --dataset <path_to_dataset>
